import os
import json
import time
import asyncio
from typing import AsyncGenerator
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import signal
import sys

from config import Config
from llm_client import LLMClient
from embedding_client import EmbeddingClient
from retriever import PaperRetriever
from pdf_parser import PDFParser
from paper_analyzer import PaperAnalyzer
from reviewer import Reviewer
from prompt_template import detect_language


def load_env_file(env_file: str):
    """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶"""
    if not os.path.isabs(env_file):
        current_dir = os.path.dirname(os.path.abspath(__file__))
        env_file = os.path.join(current_dir, env_file)
    
    if os.path.exists(env_file):
        print(f"âœ“ æ‰¾åˆ° .env æ–‡ä»¶: {env_file}")
        loaded_count = 0
        with open(env_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key] = value.strip('"\'')
                    loaded_count += 1
        print(f"âœ“ æˆåŠŸåŠ è½½ {loaded_count} ä¸ªç¯å¢ƒå˜é‡")
        return True
    else:
        print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° .env æ–‡ä»¶: {env_file}")
        return False


# åŠ è½½ç¯å¢ƒå˜é‡
load_env_file(".env")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="ICAIS2025-PaperReview API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

@app.middleware("http")
async def simple_log_middleware(request, call_next):
    """ç®€åŒ–çš„æ—¥å¿—ä¸­é—´ä»¶"""
    start_time = time.time()
    path = request.url.path
    
    if not path.startswith("/health"):
        print(f"ğŸ“¥ [{time.strftime('%H:%M:%S')}] {request.method} {path}")
    
    try:
        response = await call_next(request)
        process_time = time.time() - start_time
        if not path.startswith("/health"):
            print(f"ğŸ“¤ [{time.strftime('%H:%M:%S')}] {request.method} {path} - {response.status_code} ({process_time:.3f}s)")
        return response
    except Exception as e:
        print(f"âŒ [{time.strftime('%H:%M:%S')}] é”™è¯¯: {request.method} {path} - {e}")
        raise

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "OPTIONS"],
    allow_headers=["*"],
)

# è®¾ç½®å…¨å±€è¶…æ—¶
REQUEST_TIMEOUT = Config.REVIEW_TIMEOUT  # 20åˆ†é’Ÿæ€»è¶…æ—¶


class PaperReviewRequest(BaseModel):
    query: str
    pdf_content: str


def format_sse_data(content: str) -> str:
    """ç”ŸæˆOpenAIæ ¼å¼çš„SSEæ•°æ®
    
    æ ¼å¼ï¼šdata: {"object":"chat.completion.chunk","choices":[{"delta":{"content":"..."}}]}
    """
    data = {
        "object": "chat.completion.chunk",
        "choices": [{
            "delta": {
                "content": content
            }
        }]
    }
    # æ‰‹åŠ¨æ·»åŠ 'data: 'å‰ç¼€ï¼Œç¡®ä¿æ ¼å¼ç¬¦åˆè¦æ±‚
    return f"data: {json.dumps(data, ensure_ascii=False)}\n\n"

def format_sse_done() -> str:
    """ç”ŸæˆSSEç»“æŸæ ‡è®°
    
    æ ¼å¼ï¼šdata: [DONE]
    """
    return "data: [DONE]\n\n"

def stream_message(message: str, chunk_size: int = 1):
    """å°†æ¶ˆæ¯æŒ‰å­—ç¬¦æµå¼è¾“å‡ºï¼ˆåŒæ­¥ç”Ÿæˆå™¨ï¼‰"""
    for i in range(0, len(message), chunk_size):
        chunk = message[i:i + chunk_size]
        yield format_sse_data(chunk)


async def run_with_heartbeat(task_func, *args, heartbeat_interval=25, timeout=None, **kwargs):
    """
    æ‰§è¡Œé•¿æ—¶é—´ä»»åŠ¡ï¼ŒæœŸé—´å®šæœŸå‘é€å¿ƒè·³æ•°æ®
    
    Args:
        task_func: è¦æ‰§è¡Œçš„åŒæ­¥å‡½æ•°
        *args, **kwargs: ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°
        heartbeat_interval: å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤25ç§’
    
    Yields:
        å¿ƒè·³æ•°æ®ï¼ˆç©ºæ ¼å­—ç¬¦ï¼‰æˆ–ä»»åŠ¡ç»“æœ
    """
    import asyncio
    import time
    
    start_time = time.time()
    last_heartbeat = start_time
    
    # åˆ›å»ºä»»åŠ¡ï¼ˆä½¿ç”¨asyncio.to_threadå°†åŒæ­¥å‡½æ•°è½¬æ¢ä¸ºåç¨‹ï¼‰
    task = asyncio.create_task(asyncio.to_thread(task_func, *args, **kwargs))
    
    # åœ¨ä»»åŠ¡æ‰§è¡ŒæœŸé—´å®šæœŸå‘é€å¿ƒè·³
    while not task.done():
        await asyncio.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
        now = time.time()
        
        # å¦‚æœè¶…è¿‡å¿ƒè·³é—´éš”ï¼Œå‘é€å¿ƒè·³æ•°æ®
        if now - last_heartbeat >= heartbeat_interval:
            yield format_sse_data(" ")  # å‘é€ä¸€ä¸ªç©ºæ ¼ä½œä¸ºå¿ƒè·³
            last_heartbeat = now
        
        # å¦‚æœè®¾ç½®äº†è¶…æ—¶å¹¶ä¸”è¶…è¿‡æ€»æ—¶é•¿ï¼Œå–æ¶ˆä»»åŠ¡
        if timeout is not None and (now - start_time) > timeout:
            task.cancel()
            raise asyncio.TimeoutError(f"ä»»åŠ¡æ‰§è¡Œè¶…è¿‡ {timeout} ç§’ï¼Œå·²å–æ¶ˆ")
    
    # ç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶è¿”å›ç»“æœ
    try:
        result = await task
        # ä½¿ç”¨ç‰¹æ®Šæ ‡è®°æ¥åŒºåˆ†ç»“æœå’Œå¿ƒè·³æ•°æ®
        # è¿”å›ä¸€ä¸ªå…ƒç»„ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ ‡è®°ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ç»“æœ
        yield ("RESULT", result)
    except Exception as e:
        # å¦‚æœä»»åŠ¡å¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶é‡æ–°æŠ›å‡ºå¼‚å¸¸
        print(f"âš ï¸  ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        raise e


async def _generate_review_internal(query: str, pdf_content: str) -> AsyncGenerator[str, None]:
    """å†…éƒ¨ç”Ÿæˆå™¨å‡½æ•°ï¼Œæ‰§è¡Œå®é™…çš„è¯„é˜…é€»è¾‘"""
    start_time = time.time()
    
    try:
        # print(f"[DEBUG] å¼€å§‹æ‰§è¡Œè®ºæ–‡è¯„é˜…ï¼Œqueryé•¿åº¦: {len(query)}, pdf_contenté•¿åº¦: {len(pdf_content)}")
        
        # å…ˆæ£€æµ‹è¯­è¨€ï¼Œç”¨äºåç»­æ¶ˆæ¯æ¨¡æ¿
        language = await asyncio.to_thread(detect_language, query)
        # print(f"[DEBUG] æ£€æµ‹åˆ°è¯­è¨€: {'ä¸­æ–‡' if language == 'zh' else 'English'}")
        
        # æ ¹æ®è¯­è¨€è®¾ç½®æ¶ˆæ¯æ¨¡æ¿
        if language == 'zh':
            msg_templates = {
                'step1': "### ğŸ“„ æ­¥éª¤ 1/6: PDFè§£æä¸ç»“æ„åŒ–æå–\n\nâœ… å·²å®Œæˆ\n\n",
                'step2': "### ğŸ”‘ æ­¥éª¤ 2/6: å…³é”®ä¿¡æ¯æå–\n\nâœ… å·²å®Œæˆ\n\n",
                'step3': lambda n: (
                    "### ğŸ“š æ­¥éª¤ 3/6: ç›¸å…³è®ºæ–‡æ£€ç´¢\n\n"
                    f"âœ… å·²æ£€ç´¢åˆ° {n} ç¯‡ç›¸å…³è®ºæ–‡\n\n" if n is not None else
                    "### ğŸ“š æ­¥éª¤ 3/6: ç›¸å…³è®ºæ–‡æ£€ç´¢\n\nâœ… å·²å®Œæˆ\n\n"
                ),
                'step3_skip_degraded': "### ğŸ“š æ­¥éª¤ 3/6: ç›¸å…³è®ºæ–‡æ£€ç´¢\n\nâš ï¸ ç”±äºPDFè§£æä¿¡æ¯ä¸è¶³ï¼Œè·³è¿‡å¤–éƒ¨è®ºæ–‡æ£€ç´¢ï¼Œåç»­åˆ†æä»…åŸºäºä¸Šä¼ è®ºæ–‡å†…å®¹ã€‚\n\n",
                'step3_skip_no_query': "### ğŸ“š æ­¥éª¤ 3/6: ç›¸å…³è®ºæ–‡æ£€ç´¢\n\nâš ï¸ æ— æ³•ç”Ÿæˆæœ‰æ•ˆæŸ¥è¯¢ï¼Œè·³è¿‡å¤–éƒ¨è®ºæ–‡æ£€ç´¢ã€‚\n\n",
                'step4': "### ğŸ’¡ æ­¥éª¤ 4/6: è¯­ä¹‰åˆ†æä¸åˆ›æ–°ç‚¹è¯†åˆ«\n\nâœ… å·²å®Œæˆ\n\n",
                'step5': "### â­ æ­¥éª¤ 5/6: å¤šç»´åº¦æ·±åº¦è¯„ä¼°\n\nâœ… å·²å®Œæˆ\n\n",
                'step6': "### ğŸ“‹ æ­¥éª¤ 6/6: ç”Ÿæˆè¯„é˜…æŠ¥å‘Š\n\n",
                'error_config': "## âŒ é”™è¯¯\n\né…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®\n\n",
                'error_config_exception': lambda e: f"## âŒ é”™è¯¯\n\né…ç½®éªŒè¯å¼‚å¸¸: {e}\n\n",
                'error_llm_init': lambda e: f"## âŒ é”™è¯¯\n\nLLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}\n\n",
                'error_embedding_init': lambda e: f"## âŒ é”™è¯¯\n\nEmbeddingå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}\n\n",
                'error_retriever_init': lambda e: f"## âŒ é”™è¯¯\n\nè®ºæ–‡æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}\n\n",
                'error_pdf_parse': lambda e: f"## âŒ é”™è¯¯\n\nPDFè§£æå¤±è´¥ï¼Œæ— æ³•ç»§ç»­: {e}\n\n",
                'error_key_extraction': "## âŒ é”™è¯¯\n\nå…³é”®ä¿¡æ¯æå–å¤±è´¥\n\n",
                'error_retrieval': lambda e: f"## âŒ é”™è¯¯\n\nè®ºæ–‡æ£€ç´¢å¤±è´¥: {e}\n\n",
                'error_analysis': lambda e: f"## âŒ é”™è¯¯\n\nåˆ†æå¤±è´¥: {e}\n\n",
                'error_review': lambda e: f"## âŒ é”™è¯¯\n\nè¯„é˜…æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}\n\n",
                'error_timeout': lambda t: f"## âŒ è¶…æ—¶é”™è¯¯\n\nè¯·æ±‚å¤„ç†è¶…è¿‡ {t} ç§’ï¼Œå·²è‡ªåŠ¨ç»ˆæ­¢\n\n",
                'error_general': lambda e: f"## âŒ é”™è¯¯\n\nç¨‹åºæ‰§è¡Œå¤±è´¥: {e}\n\n",
                'pdf_timeout': "âš ï¸ PDFè§£æè¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•æå–åŸºæœ¬ä¿¡æ¯\n\n",
                'key_extraction_timeout': "âš ï¸ å…³é”®ä¿¡æ¯æå–è¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•\n\n",
                'pdf_fallback': "åŸºæœ¬ä¿¡æ¯æå–å®Œæˆ\n\n",
                'pdf_warning': lambda e: f"âš ï¸ PDFè§£æè­¦å‘Š: {e}\n\n"
            }
        else:
            msg_templates = {
                'step1': "### ğŸ“„ Step 1/6: PDF Parsing and Structure Extraction\n\nâœ… Completed\n\n",
                'step2': "### ğŸ”‘ Step 2/6: Key Information Extraction\n\nâœ… Completed\n\n",
                'step3': lambda n: (
                    "### ğŸ“š Step 3/6: Related Paper Retrieval\n\n"
                    f"âœ… Retrieved {n} related papers\n\n" if n is not None else
                    "### ğŸ“š Step 3/6: Related Paper Retrieval\n\nâœ… Completed\n\n"
                ),
                'step3_skip_degraded': "### ğŸ“š Step 3/6: Related Paper Retrieval\n\nâš ï¸ Skipped because the parsed PDF lacks reliable structure; subsequent analysis relies solely on the uploaded manuscript.\n\n",
                'step3_skip_no_query': "### ğŸ“š Step 3/6: Related Paper Retrieval\n\nâš ï¸ Skipped because no valid query could be generated from the PDF content.\n\n",
                'step4': "### ğŸ’¡ Step 4/6: Semantic Analysis and Innovation Identification\n\nâœ… Completed\n\n",
                'step5': "### â­ Step 5/6: Multi-dimensional Deep Evaluation\n\nâœ… Completed\n\n",
                'step6': "### ğŸ“‹ Step 6/6: Review Report Generation\n\n",
                'error_config': "## âŒ Error\n\nConfiguration validation failed. Please check environment variables.\n\n",
                'error_config_exception': lambda e: f"## âŒ Error\n\nConfiguration validation exception: {e}\n\n",
                'error_llm_init': lambda e: f"## âŒ Error\n\nLLM client initialization failed: {e}\n\n",
                'error_embedding_init': lambda e: f"## âŒ Error\n\nEmbedding client initialization failed: {e}\n\n",
                'error_retriever_init': lambda e: f"## âŒ Error\n\nPaper retriever initialization failed: {e}\n\n",
                'error_pdf_parse': lambda e: f"## âŒ Error\n\nPDF parsing failed. Cannot continue: {e}\n\n",
                'error_key_extraction': "## âŒ Error\n\nKey information extraction failed.\n\n",
                'error_retrieval': lambda e: f"## âŒ Error\n\nPaper retrieval failed: {e}\n\n",
                'error_analysis': lambda e: f"## âŒ Error\n\nAnalysis failed: {e}\n\n",
                'error_review': lambda e: f"## âŒ Error\n\nReview report generation failed: {e}\n\n",
                'error_timeout': lambda t: f"## âŒ Timeout Error\n\nRequest processing exceeded {t} seconds. Automatically terminated.\n\n",
                'error_general': lambda e: f"## âŒ Error\n\nProcess execution failed: {e}\n\n",
                'pdf_timeout': "âš ï¸ PDF parsing timeout, using fallback method to extract basic information\n\n",
                'key_extraction_timeout': "âš ï¸ Key information extraction timeout, using fallback method\n\n",
                'pdf_fallback': "Basic information extraction completed\n\n",
                'pdf_warning': lambda e: f"âš ï¸ PDF parsing warning: {e}\n\n"
            }
    
        # éªŒè¯é…ç½®ï¼ˆä¸è¾“å‡ºï¼‰
        # print("[DEBUG] å¼€å§‹éªŒè¯é…ç½®")
        try:
            config_valid = await asyncio.to_thread(Config.validate_config)
            if not config_valid:
                # print("[DEBUG] é…ç½®éªŒè¯å¤±è´¥")
                for chunk in stream_message(msg_templates['error_config']):
                    yield chunk
                return
            # print("[DEBUG] é…ç½®éªŒè¯æˆåŠŸ")
        except Exception as e:
            # print(f"[DEBUG] é…ç½®éªŒè¯å¼‚å¸¸: {e}")
            for chunk in stream_message(msg_templates['error_config_exception'](e)):
                yield chunk
            return
    
        # åˆ›å»ºç»„ä»¶ï¼ˆä¸è¾“å‡ºåˆå§‹åŒ–ä¿¡æ¯ï¼‰
        # print("[DEBUG] å¼€å§‹åˆå§‹åŒ–LLMå®¢æˆ·ç«¯")
        try:
            llm_client = LLMClient()
            # print("[DEBUG] LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            # print(f"[DEBUG] LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            print(traceback.format_exc())
            for chunk in stream_message(msg_templates['error_llm_init'](e)):
                yield chunk
            return
        
        # print("[DEBUG] å¼€å§‹åˆå§‹åŒ–Embeddingå®¢æˆ·ç«¯")
        try:
            embedding_client = EmbeddingClient()
            # print("[DEBUG] Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            # print(f"[DEBUG] Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            print(traceback.format_exc())
            for chunk in stream_message(msg_templates['error_embedding_init'](e)):
                yield chunk
            return
        
        # print("[DEBUG] å¼€å§‹åˆå§‹åŒ–è®ºæ–‡æ£€ç´¢å™¨")
        try:
            retriever = PaperRetriever()
            # print("[DEBUG] è®ºæ–‡æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            # print(f"[DEBUG] è®ºæ–‡æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            print(traceback.format_exc())
            for chunk in stream_message(msg_templates['error_retriever_init'](e)):
                yield chunk
            return
        
        # åˆ›å»ºè§£æå™¨ã€åˆ†æå™¨å’Œè¯„é˜…å™¨
        # print("[DEBUG] åˆ›å»ºè§£æå™¨ã€åˆ†æå™¨å’Œè¯„é˜…å™¨")
        pdf_parser = PDFParser(llm_client)
        paper_analyzer = PaperAnalyzer(llm_client, embedding_client, retriever)
        reviewer = Reviewer(llm_client)
        
        # é˜¶æ®µ1: PDFè§£æï¼ˆç®€åŒ–è¾“å‡ºï¼Œå¢åŠ å¿ƒè·³ï¼‰
        # print("[DEBUG] å¼€å§‹é˜¶æ®µ1: PDFè§£æ")
        structured_info = None
        try:
            # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºä½¿ç”¨äº†reasoneræ¨¡å‹éœ€è¦æ›´é•¿æ—¶é—´
            parse_timeout = Config.PDF_PARSE_TIMEOUT * 2  # å°†è¶…æ—¶æ—¶é—´ç¿»å€
            heartbeat_interval = 15
            async for item in run_with_heartbeat(
                pdf_parser.parse,
                pdf_content,
                parse_timeout,
                language,
                heartbeat_interval=heartbeat_interval,
                timeout=parse_timeout + 10
            ):
                if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                    structured_info = item[1]
                    break
                else:
                    yield item
        except asyncio.TimeoutError:
            # print("[DEBUG] PDFè§£æè¶…æ—¶ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æå–åŸºæœ¬ä¿¡æ¯")
            for chunk in stream_message(msg_templates['pdf_timeout']):
                yield chunk
            # è¶…æ—¶æ—¶ï¼Œå°è¯•æå–åŸºæœ¬ä¿¡æ¯
            try:
                # ç›´æ¥æå–PDFæ–‡æœ¬ï¼Œä¸è¿›è¡Œç»“æ„åŒ–è§£æ
                pdf_bytes = await asyncio.to_thread(pdf_parser.decode_base64_pdf, pdf_content)
                pdf_text = await asyncio.to_thread(pdf_parser.extract_text_from_pdf, pdf_bytes)
                
                # åˆ›å»ºåŸºæœ¬çš„ç»“æ„åŒ–ä¿¡æ¯
                structured_info = {
                    "raw_text": pdf_text[:10000],  # ä¿ç•™å‰10000å­—ç¬¦
                    "Title": "",
                    "Abstract": pdf_text[:500] if len(pdf_text) > 0 else "",  # ä½¿ç”¨å‰500å­—ç¬¦ä½œä¸ºæ‘˜è¦
                    "error": "PDFç»“æ„åŒ–è§£æè¶…æ—¶ï¼Œå·²ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æå–åŸºæœ¬ä¿¡æ¯"
                }
                
                # å°è¯•ä»æ–‡æœ¬ä¸­æå–æ ‡é¢˜ï¼ˆç®€å•æ–¹æ³•ï¼šå–ç¬¬ä¸€è¡Œæˆ–å‰100ä¸ªå­—ç¬¦ï¼‰
                lines = pdf_text.split('\n')
                for line in lines[:10]:  # æ£€æŸ¥å‰10è¡Œ
                    line = line.strip()
                    if len(line) > 10 and len(line) < 200:  # æ ‡é¢˜é€šå¸¸åœ¨10-200å­—ç¬¦ä¹‹é—´
                        structured_info["Title"] = line
                        break
                
                if not structured_info["Title"]:
                    structured_info["Title"] = pdf_text[:100].strip().replace('\n', ' ')
                
                # print("[DEBUG] å¤‡ç”¨æ–¹æ³•æå–åŸºæœ¬ä¿¡æ¯å®Œæˆ")
                for chunk in stream_message(msg_templates['pdf_fallback']):
                    yield chunk
            except Exception as e:
                # print(f"[DEBUG] å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e}")
                for chunk in stream_message(msg_templates['error_pdf_parse'](e)):
                    yield chunk
                return
        except Exception as e:
            # print(f"[DEBUG] PDFè§£æå¤±è´¥: {e}")
            import traceback
            print(traceback.format_exc())
            # å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            try:
                pdf_bytes = await asyncio.to_thread(pdf_parser.decode_base64_pdf, pdf_content)
                pdf_text = await asyncio.to_thread(pdf_parser.extract_text_from_pdf, pdf_bytes)
                structured_info = {
                    "raw_text": pdf_text[:10000],
                    "Title": pdf_text[:100].strip().replace('\n', ' ') if pdf_text else "",
                    "Abstract": pdf_text[:500] if len(pdf_text) > 0 else "",
                    "error": f"PDFè§£æå¤±è´¥: {str(e)}"
                }
                # print("[DEBUG] ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æå–åŸºæœ¬ä¿¡æ¯")
                for chunk in stream_message(msg_templates['pdf_timeout']):
                    yield chunk
                for chunk in stream_message(msg_templates['pdf_fallback']):
                    yield chunk
            except Exception as e2:
                # print(f"[DEBUG] å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                for chunk in stream_message(msg_templates['error_pdf_parse'](e2)):
                    yield chunk
                return
        
        if structured_info is None:
            for chunk in stream_message(msg_templates['error_pdf_parse']("PDF parsing returned empty result")):
                yield chunk
            return
        
        # PDFè§£æå®Œæˆåçš„debugä¿¡æ¯
        print("\n" + "="*80)
        print("[DEBUG] PDFè§£æå®Œæˆ - åˆæ­¥ç»“æœ")
        print("="*80)
        print(f"[DEBUG] structured_infoçš„é”®: {list(structured_info.keys())}")
        if "error" in structured_info:
            print(f"[DEBUG] âš ï¸ æ£€æµ‹åˆ°errorå­—æ®µ: {structured_info.get('error')}")
        if "raw_text" in structured_info:
            raw_text_len = len(structured_info.get("raw_text", ""))
            print(f"[DEBUG] raw_texté•¿åº¦: {raw_text_len} å­—ç¬¦")
        if "raw_response" in structured_info:
            raw_response_len = len(structured_info.get("raw_response", ""))
            print(f"[DEBUG] raw_responseé•¿åº¦: {raw_response_len} å­—ç¬¦")
            # æ˜¾ç¤ºraw_responseçš„å‰500å­—ç¬¦ï¼Œå¸®åŠ©è¯Šæ–­LLMè¾“å‡ºæ ¼å¼
            raw_response_preview = structured_info.get("raw_response", "")[:500]
            print(f"[DEBUG] raw_responseé¢„è§ˆ:\n{raw_response_preview}...")
        print("="*80 + "\n")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        # print("[DEBUG] æ£€æŸ¥PDFè§£æç»“æœ")
        if "error" in structured_info:
            # print(f"[DEBUG] PDFè§£ææœ‰è­¦å‘Š: {structured_info.get('error')}")
            for chunk in stream_message(msg_templates['pdf_warning'](structured_info.get('error'))):
                yield chunk
            # å¦‚æœåªæœ‰é”™è¯¯ä¿¡æ¯ï¼Œæ— æ³•ç»§ç»­
            if not structured_info.get("raw_text"):
                # print("[DEBUG] PDFè§£æå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                if language == 'zh':
                    error_msg = "## âŒ é”™è¯¯\n\nPDFè§£æå¤±è´¥ï¼Œæ— æ³•ç»§ç»­\n\n"
                else:
                    error_msg = "## âŒ Error\n\nPDF parsing failed. Cannot continue.\n\n"
                for chunk in stream_message(error_msg):
                    yield chunk
                return
        
        # è¾“å‡ºæ­¥éª¤1å®Œæˆ
        for chunk in stream_message(msg_templates['step1']):
            yield chunk
        
        # è¯¦ç»†çš„debugæ£€æŸ¥
        debug_info = paper_analyzer.debug_core_content_check(structured_info)
        has_core_sections = debug_info["has_core_content"]
        has_error = debug_info["has_error"]
        degraded_parse = (not has_core_sections) or has_error
        
        # è¾“å‡ºè¯¦ç»†çš„debugä¿¡æ¯
        print("\n" + "="*80)
        print("[DEBUG] PDFè§£æç»“æœè¯Šæ–­")
        print("="*80)
        print(f"[DEBUG] has_core_content: {has_core_sections}")
        print(f"[DEBUG] has_errorå­—æ®µ: {has_error}")
        if has_error:
            print(f"[DEBUG] erroræ¶ˆæ¯: {debug_info['error_message']}")
        print(f"[DEBUG] degraded_parse: {degraded_parse}")
        print(f"[DEBUG] structured_infoä¸­çš„æ‰€æœ‰é”®: {debug_info['all_keys']}")
        print("\n[DEBUG] æ ¸å¿ƒç« èŠ‚å­—æ®µæ£€æŸ¥ç»“æœ:")
        for section, exists in debug_info['core_sections_status'].items():
            status = "âœ“ å­˜åœ¨" if exists else "âœ— ç¼ºå¤±"
            value_preview = ""
            if exists:
                value = structured_info.get(section, "")
                value_preview = f" (å†…å®¹é¢„è§ˆ: {value[:50]}...)" if len(value) > 50 else f" (å†…å®¹: {value})"
            print(f"  {status}: {section}{value_preview}")
        print(f"\n[DEBUG] ç¼ºå¤±çš„æ ¸å¿ƒç« èŠ‚å­—æ®µ: {debug_info['missing_core_sections']}")
        if degraded_parse:
            print("\n[DEBUG] âš ï¸ è§¦å‘degraded_parseçš„åŸå› :")
            if not has_core_sections:
                print("  - åŸå› 1: has_core_content() è¿”å› False (æ‰€æœ‰æ ¸å¿ƒç« èŠ‚å­—æ®µéƒ½ç¼ºå¤±)")
            if has_error:
                print(f"  - åŸå› 2: structured_info ä¸­å­˜åœ¨ 'error' å­—æ®µ: {debug_info['error_message']}")
        print("="*80 + "\n")
        
        # é˜¶æ®µ2: å…³é”®ä¿¡æ¯æå–ä¸æŸ¥è¯¢æ„å»ºï¼ˆç®€åŒ–è¾“å‡ºï¼Œå¢åŠ å¿ƒè·³ï¼‰
        # print("[DEBUG] å¼€å§‹é˜¶æ®µ2: å…³é”®ä¿¡æ¯æå–")
        try:
            # åªæå–å…³é”®è¯ï¼Œä¸è¿›è¡Œå®Œæ•´åˆ†æï¼ˆèŠ‚çœæ—¶é—´ï¼‰
            # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œå› ä¸ºä½¿ç”¨äº†reasoneræ¨¡å‹éœ€è¦æ›´é•¿æ—¶é—´
            extraction_timeout = Config.KEY_EXTRACTION_TIMEOUT * 2  # å°†è¶…æ—¶æ—¶é—´ç¿»å€
            heartbeat_interval = 15
            keywords = []
            async for item in run_with_heartbeat(
                paper_analyzer.extract_keywords,
                structured_info,
                extraction_timeout,
                language,
                heartbeat_interval=heartbeat_interval,
                timeout=extraction_timeout + 10
            ):
                if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                    keywords = item[1] or []
                    break
                else:
                    yield item
            query = await asyncio.to_thread(paper_analyzer.build_query, keywords, structured_info)
            # print(f"[DEBUG] å…³é”®è¯æå–å®Œæˆ: {keywords}")
        except asyncio.TimeoutError:
            # print("[DEBUG] å…³é”®ä¿¡æ¯æå–è¶…æ—¶ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            for chunk in stream_message(msg_templates['key_extraction_timeout']):
                yield chunk
            # ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æå–å…³é”®è¯
            keywords = await asyncio.to_thread(paper_analyzer._extract_fallback_keywords, structured_info)
            query = await asyncio.to_thread(paper_analyzer.build_query, keywords, structured_info)
            # print(f"[DEBUG] å¤‡ç”¨æ–¹æ³•æå–å…³é”®è¯å®Œæˆ: {keywords}")
        except Exception as e:
            # print(f"[DEBUG] å…³é”®ä¿¡æ¯æå–å¤±è´¥: {e}")
            for chunk in stream_message(msg_templates['error_key_extraction']):
                yield chunk
            return
        
        # è¾“å‡ºæ­¥éª¤2å®Œæˆ
        for chunk in stream_message(msg_templates['step2']):
            yield chunk
        
        # é˜¶æ®µ3: ç›¸å…³è®ºæ–‡æ£€ç´¢ï¼ˆç®€åŒ–è¾“å‡ºï¼‰
        # print("[DEBUG] å¼€å§‹é˜¶æ®µ3: ç›¸å…³è®ºæ–‡æ£€ç´¢")
        related_papers = []
        skip_reason_key = None
        if not query:
            skip_reason_key = 'step3_skip_no_query'
        elif degraded_parse:
            skip_reason_key = 'step3_skip_degraded'
        
        if skip_reason_key:
            for chunk in stream_message(msg_templates[skip_reason_key]):
                yield chunk
        else:
            if query:
                try:
                    heartbeat_interval = 15
                    async for item in run_with_heartbeat(
                        paper_analyzer.retrieve_related_papers,
                        query,
                        keywords,
                        Config.RETRIEVAL_TIMEOUT,
                        heartbeat_interval=heartbeat_interval,
                        timeout=Config.RETRIEVAL_TIMEOUT + 10
                    ):
                        if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                            related_papers = item[1] or []
                            break
                        else:
                            yield item
                except Exception as e:
                    import traceback
                    print(traceback.format_exc())
                    related_papers = []
            for chunk in stream_message(msg_templates['step3'](len(related_papers))):
                yield chunk
        
        # é˜¶æ®µ4: è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æä¸åˆ›æ–°ç‚¹è¯†åˆ«ï¼ˆç®€åŒ–è¾“å‡ºï¼Œå¢åŠ å¿ƒè·³é˜²æ­¢è¶…æ—¶ï¼‰
        # print("[DEBUG] å¼€å§‹é˜¶æ®µ4: è¯­ä¹‰åˆ†æä¸åˆ›æ–°ç‚¹è¯†åˆ«")
        innovation_analysis = ""
        
        # æ ¼å¼åŒ–ç»“æ„åŒ–ä¿¡æ¯ä¸ºæ–‡æœ¬
        paper_text = paper_analyzer._format_structured_info(structured_info)
        semantic_similarities = []
        heartbeat_interval = 15
        
        if related_papers:
            # æœ‰ç›¸å…³è®ºæ–‡æ—¶ï¼Œå…ˆè®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œå†è¿›è¡Œåˆ›æ–°ç‚¹åˆ†æ
            try:
                async for item in run_with_heartbeat(
                    paper_analyzer.calculate_semantic_similarity,
                    paper_text,
                    related_papers,
                    heartbeat_interval=heartbeat_interval,
                    timeout=Config.SEMANTIC_ANALYSIS_TIMEOUT
                ):
                    if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                        semantic_similarities = item[1] or []
                    else:
                        yield item
                
                async for item in run_with_heartbeat(
                    paper_analyzer.analyze_innovation,
                    structured_info,
                    related_papers,
                    Config.SEMANTIC_ANALYSIS_TIMEOUT,
                    language,
                    heartbeat_interval=heartbeat_interval,
                    timeout=Config.SEMANTIC_ANALYSIS_TIMEOUT + 10
                ):
                    if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                        innovation_analysis = item[1] or ""
                    else:
                        yield item
            except asyncio.TimeoutError:
                # print("[DEBUG] è¯­ä¹‰åˆ†æé˜¶æ®µè¶…æ—¶")
                for chunk in stream_message(msg_templates['error_analysis']("è¯­ä¹‰åˆ†æé˜¶æ®µè¶…æ—¶")):
                    yield chunk
                if language == 'zh':
                    innovation_analysis = "è¯­ä¹‰åˆ†æé˜¶æ®µè¶…æ—¶ï¼Œä½¿ç”¨è®ºæ–‡è‡ªèº«ä¿¡æ¯è¿›è¡ŒåŸºæœ¬åˆ›æ–°ç‚¹æ€»ç»“ã€‚"
                else:
                    innovation_analysis = "Semantic analysis timed out. Falling back to a basic innovation summary based on the paper content only."
            except Exception as e:
                import traceback
                print(traceback.format_exc())
                for chunk in stream_message(msg_templates['error_analysis'](e)):
                    yield chunk
                innovation_analysis = ""
        else:
            # æ²¡æœ‰ç›¸å…³è®ºæ–‡æ—¶ï¼ŒåŸºäºè®ºæ–‡æœ¬èº«è¿›è¡Œåˆ›æ–°ç‚¹åˆ†æï¼ŒåŒæ—¶å‘é€å¿ƒè·³
            try:
                async for item in run_with_heartbeat(
                    paper_analyzer.analyze_innovation,
                    structured_info,
                    [],
                    Config.SEMANTIC_ANALYSIS_TIMEOUT,
                    language,
                    heartbeat_interval=heartbeat_interval,
                    timeout=Config.SEMANTIC_ANALYSIS_TIMEOUT + 10
                ):
                    if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                        innovation_analysis = item[1] or ""
                    else:
                        yield item
            except asyncio.TimeoutError:
                if language == 'zh':
                    innovation_analysis = "åˆ›æ–°ç‚¹åˆ†æè¶…æ—¶ï¼Œä½¿ç”¨è®ºæ–‡è‡ªèº«ä¿¡æ¯è¿›è¡ŒåŸºæœ¬æ€»ç»“ã€‚"
                else:
                    innovation_analysis = "Innovation analysis timed out. Falling back to a basic summary from the paper itself."
            except Exception as e:
                import traceback
                print(traceback.format_exc())
                if language == 'zh':
                    innovation_analysis = f"åˆ›æ–°ç‚¹åˆ†æå¤±è´¥: {str(e)}"
                else:
                    innovation_analysis = f"Innovation analysis failed: {str(e)}"
        
        # è¾“å‡ºæ­¥éª¤4å®Œæˆ
        for chunk in stream_message(msg_templates['step4']):
            yield chunk
        
        # é˜¶æ®µ5: å¤šç»´åº¦æ·±åº¦è¯„ä¼°ï¼ˆç®€åŒ–è¾“å‡ºï¼Œåœ¨reviewer.reviewä¸­å®Œæˆï¼‰
        # print("[DEBUG] å¼€å§‹é˜¶æ®µ5: å¤šç»´åº¦æ·±åº¦è¯„ä¼°")
        # è¾“å‡ºæ­¥éª¤5å®Œæˆï¼ˆè¯„ä¼°åœ¨reviewer.reviewä¸­å®Œæˆï¼‰
        for chunk in stream_message(msg_templates['step5']):
            yield chunk
        
        # é˜¶æ®µ6: ç”Ÿæˆè¯„é˜…æŠ¥å‘Šï¼ˆå®Œæ•´è¾“å‡ºï¼‰
        # print("[DEBUG] å¼€å§‹é˜¶æ®µ6: ç”Ÿæˆè¯„é˜…æŠ¥å‘Š")
        for chunk in stream_message(msg_templates['step6']):
            yield chunk
        
        # å‘é€è¿›åº¦æç¤º
        if language == 'zh':
            progress_msg = "ğŸ”„ æ­£åœ¨ç”Ÿæˆè¯„é˜…æŠ¥å‘Šï¼Œè¯·ç¨å€™...\n\n"
        else:
            progress_msg = "ğŸ”„ Generating review report, please wait...\n\n"
        for chunk in stream_message(progress_msg):
            yield chunk
        
        try:
            # print(f"[DEBUG] å¼€å§‹ç”Ÿæˆè¯„é˜…æŠ¥å‘Šï¼Œè¶…æ—¶æ—¶é—´: {Config.EVALUATION_TIMEOUT + Config.REPORT_GENERATION_TIMEOUT + 20}ç§’")
            review = None
            async for item in run_with_heartbeat(
                reviewer.review,
                structured_info, innovation_analysis, related_papers, 
                Config.EVALUATION_TIMEOUT + Config.REPORT_GENERATION_TIMEOUT, language,
                heartbeat_interval=25,
                timeout=Config.EVALUATION_TIMEOUT + Config.REPORT_GENERATION_TIMEOUT + 20
            ):
                if isinstance(item, tuple) and len(item) == 2 and item[0] == "RESULT":
                    review = item[1]
                    # print(f"[DEBUG] è¯„é˜…æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(review) if review else 0} å­—ç¬¦")
                    break
                else:
                    yield item
            
            if not review or review.strip() == "":
                # print(f"[DEBUG] è¯„é˜…æŠ¥å‘Šä¸ºç©º: review={review}")
                if language == 'zh':
                    error_msg = "âš ï¸ è¯„é˜…æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¿”å›ç©ºå†…å®¹\n\n"
                else:
                    error_msg = "âš ï¸ Review report generation failed, returned empty content\n\n"
                for chunk in stream_message(error_msg):
                    yield chunk
            else:
                # æµå¼è¾“å‡ºè¯„é˜…æŠ¥å‘Š
                for chunk in stream_message(f"{review}\n\n"):
                    yield chunk
        except asyncio.TimeoutError:
            # print("[DEBUG] è¯„é˜…æŠ¥å‘Šç”Ÿæˆè¶…æ—¶")
            if language == 'zh':
                error_msg = "## âŒ é”™è¯¯\n\nè¯„é˜…æŠ¥å‘Šç”Ÿæˆè¶…æ—¶\n\n"
            else:
                error_msg = "## âŒ Error\n\nReview report generation timeout\n\n"
            for chunk in stream_message(error_msg):
                yield chunk
            return
        except Exception as e:
            # print(f"[DEBUG] è¯„é˜…æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            print(traceback.format_exc())
            for chunk in stream_message(msg_templates['error_review'](e)):
                yield chunk
            return
    
        elapsed = time.time() - start_time
        # print(f"[DEBUG] è®ºæ–‡è¯„é˜…å®Œæˆï¼Œæ€»è€—æ—¶: {elapsed:.2f}ç§’")
        # ä¸è¾“å‡ºæ€»è€—æ—¶åˆ°æµå¼å“åº”ï¼Œä¿æŒè¾“å‡ºç®€æ´
    
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"âŒ [_generate_review_internal] æœªæ•è·çš„å¼‚å¸¸: {e}\n{error_trace}")
        # ç¡®ä¿å¼‚å¸¸ä¿¡æ¯é€šè¿‡SSEæµå‘é€
        try:
            # æ£€æµ‹è¯­è¨€ä»¥ä½¿ç”¨æ­£ç¡®çš„é”™è¯¯æ¶ˆæ¯
            try:
                language = await asyncio.to_thread(detect_language, query)
                if language == 'zh':
                    error_msg = f"## âŒ é”™è¯¯\n\nç¨‹åºæ‰§è¡Œå¤±è´¥: {e}\n\n```\n{error_trace}\n```\n\n"
                else:
                    error_msg = f"## âŒ Error\n\nProcess execution failed: {e}\n\n```\n{error_trace}\n```\n\n"
            except:
                # å¦‚æœæ£€æµ‹è¯­è¨€å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡
                error_msg = f"## âŒ Error\n\nProcess execution failed: {e}\n\n```\n{error_trace}\n```\n\n"
            for chunk in stream_message(error_msg):
                yield chunk
        except Exception as send_error:
            print(f"âŒ å‘é€é”™è¯¯ä¿¡æ¯æ—¶å¤±è´¥: {send_error}")
            # å¦‚æœå‘é€å¤±è´¥ï¼Œè‡³å°‘å°è¯•å‘é€ä¸€ä¸ªç®€å•çš„é”™è¯¯æ¶ˆæ¯
            try:
                yield format_sse_data(f"## âŒ Error\n\nProcess execution failed: {e}\n\n")
            except:
                pass


async def generate_review_stream(query: str, pdf_content: str) -> AsyncGenerator[str, None]:
    """ç”Ÿæˆè¯„é˜…çš„æµå¼è¾“å‡ºç”Ÿæˆå™¨ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰"""
    start_time = time.time()
    # print(f"[DEBUG] [generate_review_stream] ç”Ÿæˆå™¨å¯åŠ¨ï¼Œqueryé•¿åº¦: {len(query)}, pdf_contenté•¿åº¦: {len(pdf_content)}")
    
    try:
        item_count = 0
        async for item in _generate_review_internal(query, pdf_content):
            item_count += 1
            # if item_count % 100 == 0:
            #     print(f"[DEBUG] [generate_review_stream] å·²yield {item_count} ä¸ªchunk")
            
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            elapsed = time.time() - start_time
            if elapsed > REQUEST_TIMEOUT:
                # print(f"[DEBUG] [generate_review_stream] è¯·æ±‚è¶…æ—¶ï¼Œå·²å¤„ç† {item_count} ä¸ªchunk")
                # æ£€æµ‹è¯­è¨€ä»¥ä½¿ç”¨æ­£ç¡®çš„é”™è¯¯æ¶ˆæ¯
                try:
                    language = await asyncio.to_thread(detect_language, query)
                    if language == 'zh':
                        timeout_msg = f"## âŒ è¶…æ—¶é”™è¯¯\n\nè¯·æ±‚å¤„ç†è¶…è¿‡ {REQUEST_TIMEOUT} ç§’ï¼Œå·²è‡ªåŠ¨ç»ˆæ­¢\n\n"
                    else:
                        timeout_msg = f"## âŒ Timeout Error\n\nRequest processing exceeded {REQUEST_TIMEOUT} seconds. Automatically terminated.\n\n"
                except:
                    timeout_msg = f"## âŒ Timeout Error\n\nRequest processing exceeded {REQUEST_TIMEOUT} seconds. Automatically terminated.\n\n"
                for chunk in stream_message(timeout_msg):
                    yield chunk
                yield format_sse_done()
                return
            yield item
        
        # print(f"[DEBUG] [generate_review_stream] ç”Ÿæˆå™¨æ­£å¸¸å®Œæˆï¼Œå…±yield {item_count} ä¸ªchunk")
        # å‘é€ç»“æŸæ ‡è®°
        yield format_sse_done()
                
    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"âŒ [generate_review_stream] ç”Ÿæˆå™¨é”™è¯¯: {e}\n{error_trace}")
        try:
            # æ£€æµ‹è¯­è¨€ä»¥ä½¿ç”¨æ­£ç¡®çš„é”™è¯¯æ¶ˆæ¯
            try:
                language = await asyncio.to_thread(detect_language, query)
                if language == 'zh':
                    error_msg = f"## âŒ é”™è¯¯\n\nç¨‹åºæ‰§è¡Œå¤±è´¥: {e}\n\n```\n{error_trace}\n```\n\n"
                else:
                    error_msg = f"## âŒ Error\n\nProcess execution failed: {e}\n\n```\n{error_trace}\n```\n\n"
            except:
                # å¦‚æœæ£€æµ‹è¯­è¨€å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡
                error_msg = f"## âŒ Error\n\nProcess execution failed: {e}\n\n```\n{error_trace}\n```\n\n"
            for chunk in stream_message(error_msg):
                yield chunk
            yield format_sse_done()
        except Exception as send_error:
            print(f"âŒ [generate_review_stream] å‘é€é”™è¯¯ä¿¡æ¯æ—¶å¤±è´¥: {send_error}")
            try:
                yield format_sse_data(f"## âŒ Error\n\nProcess execution failed: {e}\n\n")
                yield format_sse_done()
            except:
                pass


@app.post("/paper_review")
async def paper_review(request: PaperReviewRequest):
    """
    è®ºæ–‡è¯„é˜…APIç«¯ç‚¹
    """
    if not request.query or not request.query.strip():
        raise HTTPException(status_code=400, detail="Query cannot be empty")
    
    if not request.pdf_content or not request.pdf_content.strip():
        raise HTTPException(status_code=400, detail="PDF content cannot be empty")
    
    return StreamingResponse(
        generate_review_stream(request.query, request.pdf_content),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Access-Control-Allow-Origin": "*"
        }
    )


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "ok", "service": "ICAIS2025-PaperReview API", "timestamp": time.time()}


@app.get("/")
async def root():
    """æ ¹ç«¯ç‚¹"""
    return {
        "service": "ICAIS2025-PaperReview API",
        "version": "1.0.0",
        "health": "http://localhost:3000/health",
        "docs": "http://localhost:3000/docs",
        "paper_review": "POST /paper_review"
    }


# ä¼˜é›…å…³é—­å¤„ç†
def shutdown_handler(signum, frame):
    print(f"\nâš ï¸ æ”¶åˆ°ç»ˆæ­¢ä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    sys.exit(0)


signal.signal(signal.SIGINT, shutdown_handler)
signal.signal(signal.SIGTERM, shutdown_handler)

if __name__ == "__main__":
    import uvicorn
    
    # éªŒè¯ç«¯å£å¯ç”¨æ€§
    import socket
    def check_port(port):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            try:
                s.bind(("0.0.0.0", port))
                return True
            except OSError:
                return False
    
    if not check_port(3000):
        print(f"âŒ ç«¯å£3000å·²è¢«å ç”¨ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æœåŠ¡åœ¨ä½¿ç”¨")
        sys.exit(1)
    
    print("ğŸš€ å¯åŠ¨ FastAPI æœåŠ¡...")
    print(f"ğŸ“ ç›‘å¬åœ°å€: http://0.0.0.0:3000")
    print(f"ğŸ“ å¥åº·æ£€æŸ¥: curl http://localhost:3000/health")
    print(f"ğŸ“š APIæ–‡æ¡£: http://localhost:3000/docs")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=3000,
        log_level="info",
        access_log=True,
        reload=False,
        workers=1,
        loop="asyncio",
        timeout_keep_alive=30,
        limit_concurrency=100,
    )

